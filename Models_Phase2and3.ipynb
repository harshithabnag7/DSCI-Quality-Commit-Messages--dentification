{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95e8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_1 = pd.read_excel('ApacheSample.xlsx')\n",
    "df_2 = pd.read_excel('junitSample.xlsx')\n",
    "df_3 = pd.read_excel('okhttpSample.xlsx')\n",
    "df_4 = pd.read_excel('retrofitSample.xlsx')\n",
    "df_5 = pd.read_excel('springBootSample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2d45056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "      <th>if_mulit_commit</th>\n",
       "      <th>message</th>\n",
       "      <th>new_message1</th>\n",
       "      <th>authorEmail</th>\n",
       "      <th>commitDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3079</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/1b2e6dc...</td>\n",
       "      <td>1</td>\n",
       "      <td>remove some magic value (#4752) &lt;enter&gt;  &lt;ente...</td>\n",
       "      <td>remove some magic value ( &lt;pr_link&gt; )  &lt;enter&gt;...</td>\n",
       "      <td>developer128</td>\n",
       "      <td>2019-08-06T07:23:45Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4224</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/9e9e778...</td>\n",
       "      <td>0</td>\n",
       "      <td>Optimize_hessian_desr_performance (#1705)</td>\n",
       "      <td>Optimize_hessian_desr_performance ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer130</td>\n",
       "      <td>2018-04-26T10:51:02Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3817</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/7f262f9...</td>\n",
       "      <td>0</td>\n",
       "      <td>simplify map empty judgment (#3376)</td>\n",
       "      <td>simplify map empty judgment ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer133</td>\n",
       "      <td>2019-01-29T05:38:51Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/ed7be11...</td>\n",
       "      <td>0</td>\n",
       "      <td>constant names should be all uppercase, separa...</td>\n",
       "      <td>constant names should be all uppercase, separa...</td>\n",
       "      <td>developer134</td>\n",
       "      <td>2020-02-01T06:58:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/912303d...</td>\n",
       "      <td>0</td>\n",
       "      <td>collect async export services (#5905)</td>\n",
       "      <td>collect async export services ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer135</td>\n",
       "      <td>2020-04-01T14:49:58Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2884</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/dfa8499...</td>\n",
       "      <td>0</td>\n",
       "      <td>fix NetUtils.isPreferIPV6Address bug (#5238)</td>\n",
       "      <td>fix  &lt;method_name&gt;  bug ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer137</td>\n",
       "      <td>2019-11-08T05:20:57Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3868</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/c21cc05...</td>\n",
       "      <td>0</td>\n",
       "      <td>replace ServiceAnnotationBeanPostProcessor log...</td>\n",
       "      <td>replace  &lt;file_name&gt;  log.isInfoEnabled-&gt;log.i...</td>\n",
       "      <td>developer140</td>\n",
       "      <td>2018-10-31T03:29:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2599</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/317e62f...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix concurrency problems in RpcStatus and Roun...</td>\n",
       "      <td>Fix concurrency problems in  &lt;file_name&gt;  and ...</td>\n",
       "      <td>developer145</td>\n",
       "      <td>2020-04-07T02:43:21Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4415</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/6a77179...</td>\n",
       "      <td>0</td>\n",
       "      <td>Update OverrideServiceImpl.java &lt;enter&gt;  &lt;ente...</td>\n",
       "      <td>Update  &lt;file_name&gt; &lt;enter&gt; fix the bug: cant ...</td>\n",
       "      <td>developer150</td>\n",
       "      <td>2017-10-10T09:06:02Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/71e04fb...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix #1411 Java Locale use '_' split language, ...</td>\n",
       "      <td>Fix &lt;issue_link&gt; Java &lt;iden&gt; use '_' split lan...</td>\n",
       "      <td>developer152</td>\n",
       "      <td>2018-04-04T03:01:26Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2606</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/d6672af...</td>\n",
       "      <td>0</td>\n",
       "      <td>polish NetUtils#matchIpRange (#5773)</td>\n",
       "      <td>polish  &lt;method_name&gt;  ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer154</td>\n",
       "      <td>2020-04-02T13:23:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2912</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/15d8084...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix Dubbo-3990 #3990 (#5247)</td>\n",
       "      <td>Fix Dubbo-3990 &lt;issue_link&gt; ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer157</td>\n",
       "      <td>2019-10-29T01:48:17Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2811</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/53dca53...</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove redundant judgment (#5456)</td>\n",
       "      <td>Remove redundant judgment ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer175</td>\n",
       "      <td>2019-12-11T08:37:21Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/5668d74...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fix export provider error, change to catch thr...</td>\n",
       "      <td>Fix export provider error, change to catch thr...</td>\n",
       "      <td>developer182</td>\n",
       "      <td>2020-07-01T03:42:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4050</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/apache/dubbo/commit/bcb6eee...</td>\n",
       "      <td>0</td>\n",
       "      <td>fix return type (#3284)</td>\n",
       "      <td>fix return type ( &lt;pr_link&gt; )</td>\n",
       "      <td>developer202</td>\n",
       "      <td>2019-01-21T03:15:02Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  repo_id  label                                                url  \\\n",
       "0   3079        2      0  https://github.com/apache/dubbo/commit/1b2e6dc...   \n",
       "1   4224        2      0  https://github.com/apache/dubbo/commit/9e9e778...   \n",
       "2   3817        2      0  https://github.com/apache/dubbo/commit/7f262f9...   \n",
       "3   2727        2      2  https://github.com/apache/dubbo/commit/ed7be11...   \n",
       "4   2613        2      0  https://github.com/apache/dubbo/commit/912303d...   \n",
       "5   2884        2      2  https://github.com/apache/dubbo/commit/dfa8499...   \n",
       "6   3868        2      0  https://github.com/apache/dubbo/commit/c21cc05...   \n",
       "7   2599        2      2  https://github.com/apache/dubbo/commit/317e62f...   \n",
       "8   4415        2      2  https://github.com/apache/dubbo/commit/6a77179...   \n",
       "9   4221        2      0  https://github.com/apache/dubbo/commit/71e04fb...   \n",
       "10  2606        2      0  https://github.com/apache/dubbo/commit/d6672af...   \n",
       "11  2912        2      2  https://github.com/apache/dubbo/commit/15d8084...   \n",
       "12  2811        2      0  https://github.com/apache/dubbo/commit/53dca53...   \n",
       "13  2525        2      0  https://github.com/apache/dubbo/commit/5668d74...   \n",
       "14  4050        2      2  https://github.com/apache/dubbo/commit/bcb6eee...   \n",
       "\n",
       "    if_mulit_commit                                            message  \\\n",
       "0                 1  remove some magic value (#4752) <enter>  <ente...   \n",
       "1                 0          Optimize_hessian_desr_performance (#1705)   \n",
       "2                 0                simplify map empty judgment (#3376)   \n",
       "3                 0  constant names should be all uppercase, separa...   \n",
       "4                 0              collect async export services (#5905)   \n",
       "5                 0       fix NetUtils.isPreferIPV6Address bug (#5238)   \n",
       "6                 0  replace ServiceAnnotationBeanPostProcessor log...   \n",
       "7                 0  Fix concurrency problems in RpcStatus and Roun...   \n",
       "8                 0  Update OverrideServiceImpl.java <enter>  <ente...   \n",
       "9                 0  Fix #1411 Java Locale use '_' split language, ...   \n",
       "10                0               polish NetUtils#matchIpRange (#5773)   \n",
       "11                0                       Fix Dubbo-3990 #3990 (#5247)   \n",
       "12                0                  Remove redundant judgment (#5456)   \n",
       "13                0  Fix export provider error, change to catch thr...   \n",
       "14                0                            fix return type (#3284)   \n",
       "\n",
       "                                         new_message1   authorEmail  \\\n",
       "0   remove some magic value ( <pr_link> )  <enter>...  developer128   \n",
       "1    Optimize_hessian_desr_performance ( <pr_link> )   developer130   \n",
       "2          simplify map empty judgment ( <pr_link> )   developer133   \n",
       "3   constant names should be all uppercase, separa...  developer134   \n",
       "4        collect async export services ( <pr_link> )   developer135   \n",
       "5              fix  <method_name>  bug ( <pr_link> )   developer137   \n",
       "6   replace  <file_name>  log.isInfoEnabled->log.i...  developer140   \n",
       "7   Fix concurrency problems in  <file_name>  and ...  developer145   \n",
       "8   Update  <file_name> <enter> fix the bug: cant ...  developer150   \n",
       "9   Fix <issue_link> Java <iden> use '_' split lan...  developer152   \n",
       "10              polish  <method_name>  ( <pr_link> )   developer154   \n",
       "11         Fix Dubbo-3990 <issue_link> ( <pr_link> )   developer157   \n",
       "12           Remove redundant judgment ( <pr_link> )   developer175   \n",
       "13  Fix export provider error, change to catch thr...  developer182   \n",
       "14                     fix return type ( <pr_link> )   developer202   \n",
       "\n",
       "              commitDate  \n",
       "0   2019-08-06T07:23:45Z  \n",
       "1   2018-04-26T10:51:02Z  \n",
       "2   2019-01-29T05:38:51Z  \n",
       "3   2020-02-01T06:58:09Z  \n",
       "4   2020-04-01T14:49:58Z  \n",
       "5   2019-11-08T05:20:57Z  \n",
       "6   2018-10-31T03:29:54Z  \n",
       "7   2020-04-07T02:43:21Z  \n",
       "8   2017-10-10T09:06:02Z  \n",
       "9   2018-04-04T03:01:26Z  \n",
       "10  2020-04-02T13:23:04Z  \n",
       "11  2019-10-29T01:48:17Z  \n",
       "12  2019-12-11T08:37:21Z  \n",
       "13  2020-07-01T03:42:09Z  \n",
       "14  2019-01-21T03:15:02Z  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c852fa",
   "metadata": {},
   "source": [
    "# Log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "449de924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def mylog():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logfile = \"./log/\" + str(datetime.datetime.now().month) + \"-\" + str(datetime.datetime.now().day) + \"-\" + str(\n",
    "        datetime.datetime.now().hour) + \"-\" + str(datetime.datetime.now().minute) + \\\n",
    "              os.path.split(__file__)[-1].split(\".\")[0] + '.log'\n",
    "    fileHandler = logging.FileHandler(logfile, mode='w', encoding='UTF-8')\n",
    "    fileHandler.setLevel(logging.NOTSET)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger\n",
    "\n",
    "# Define the preprocess_text function to perform text preprocessing steps\n",
    "def preprocess_text(text):\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Perform stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_text = [stemmer.stem(word) for word in filtered_text]\n",
    "\n",
    "    # Join the processed words back into a single string\n",
    "    preprocessed_text = ' '.join(stemmed_text)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess the commit message text\n",
    "df_1['new_message1'] = df_1['new_message1'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(df_1, test_size=0.15, random_state=42)\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['new_message1'])\n",
    "X_test = vectorizer.transform(test_data['new_message1'])\n",
    "\n",
    "# Specify the column name for the labels\n",
    "label_column = 'label'\n",
    "\n",
    "# Get the corresponding labels for the training and test sets\n",
    "y_train = train_data[label_column]\n",
    "y_test = test_data[label_column]\n",
    "\n",
    "# Train the model (replace with your desired classifier)\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40593b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10fe8267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 0, 0, 0, 0, 2, 3, 2, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 2, 0,\n",
       "       0, 2, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d18074a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Overall): 0.64\n",
      "Accuracy (c-why and c-what): 0.8064516129032258\n",
      "Training set shape: (278, 9)\n",
      "Test set shape: (50, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the function to configure logging\n",
    "def mylog():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logfile = \"./log/\" + str(datetime.datetime.now().month) + \"-\" + str(datetime.datetime.now().day) + \"-\" + str(\n",
    "        datetime.datetime.now().hour) + \"-\" + str(datetime.datetime.now().minute) + \\\n",
    "              os.path.split(__file__)[-1].split(\".\")[0] + '.log'\n",
    "    fileHandler = logging.FileHandler(logfile, mode='w', encoding='UTF-8')\n",
    "    fileHandler.setLevel(logging.NOTSET)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "df = pd.read_excel('ApacheSample.xlsx')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "label_column = 'label'  # Column name for the labels\n",
    "message_column = 'new_message1'  # Column name for the preprocessed messages\n",
    "\n",
    "# Get the corresponding labels for the test set\n",
    "test_labels = test_data[label_column]\n",
    "\n",
    "# Replace 'predictions' with your actual predictions for the test set\n",
    "predictions = np.array([3, 0, 1, 0, 0, 0, 0, 2, 3, 2, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 0, 0])  # Replace 'model' with your trained model and 'X_test' with your test data\n",
    "\n",
    "# Calculate accuracy for the whole test set\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy (Overall):\", accuracy)\n",
    "\n",
    "# Filter the test labels and predictions for c-why and c-what categories (label = 0)\n",
    "c_why_what_labels = test_labels[test_labels == 0]\n",
    "c_why_what_predictions = predictions[test_labels == 0]\n",
    "\n",
    "# Calculate accuracy for c-why and c-what combined category\n",
    "c_why_what_accuracy = accuracy_score(c_why_what_labels, c_why_what_predictions)\n",
    "print(\"Accuracy (c-why and c-what):\", c_why_what_accuracy)\n",
    "\n",
    "# Verify the shapes of the training and test sets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Test set shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8bf49",
   "metadata": {},
   "source": [
    "# for df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc5d7b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3877551020408163\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def mylog():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logfile = \"./log/\" + str(datetime.datetime.now().month) + \"-\" + str(datetime.datetime.now().day) + \"-\" + str(\n",
    "        datetime.datetime.now().hour) + \"-\" + str(datetime.datetime.now().minute) + \\\n",
    "              os.path.split(__file__)[-1].split(\".\")[0] + '.log'\n",
    "    fileHandler = logging.FileHandler(logfile, mode='w', encoding='UTF-8')\n",
    "    fileHandler.setLevel(logging.NOTSET)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger\n",
    "\n",
    "# Define the preprocess_text function to perform text preprocessing steps\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_text = [stemmer.stem(word) for word in filtered_text]\n",
    "        preprocessed_text = ' '.join(stemmed_text)\n",
    "        return preprocessed_text\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Preprocess the commit message text\n",
    "df_2['new_message1'] = df_2['new_message1'].apply(preprocess_text)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(df_2, test_size=0.15, random_state=42)\n",
    "\n",
    "# Extract features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['new_message1'])\n",
    "X_test = vectorizer.transform(test_data['new_message1'])\n",
    "\n",
    "label_column = 'label'\n",
    "\n",
    "\n",
    "y_train = train_data[label_column]\n",
    "y_test = test_data[label_column]\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions_2 = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_2 = accuracy_score(y_test, predictions_2)\n",
    "print(\"Accuracy:\", accuracy_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0081818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0,\n",
       "       3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 0, 0,\n",
       "       0, 3, 3, 0, 3])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5b83049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Overall): 0.3877551020408163\n",
      "Accuracy (c-why and c-what): 0.6666666666666666\n",
      "Training set shape: (274, 9)\n",
      "Test set shape: (49, 9)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the function to configure logging\n",
    "def mylog():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logfile = \"./log/\" + str(datetime.datetime.now().month) + \"-\" + str(datetime.datetime.now().day) + \"-\" + str(\n",
    "        datetime.datetime.now().hour) + \"-\" + str(datetime.datetime.now().minute) + \\\n",
    "              os.path.split(__file__)[-1].split(\".\")[0] + '.log'\n",
    "    fileHandler = logging.FileHandler(logfile, mode='w', encoding='UTF-8')\n",
    "    fileHandler.setLevel(logging.NOTSET)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fileHandler.setFormatter(formatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(df_2, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "label_column = 'label'  # Column name for the labels\n",
    "message_column = 'new_message1'  # Column name for the preprocessed messages\n",
    "\n",
    "# Get the corresponding labels for the test set\n",
    "test_labels = test_data[label_column]\n",
    "\n",
    "# Replace 'predictions' with your actual predictions for the test set\n",
    "predictions =  np.array([1, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0,\n",
    "       3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 0, 0,\n",
    "       0, 3, 3, 0, 3])  # Replace 'model' with your trained model and 'X_test' with your test data\n",
    "\n",
    "# Calculate accuracy for the whole test set\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy (Overall):\", accuracy)\n",
    "\n",
    "# Filter the test labels and predictions for c-why and c-what categories (label = 0)\n",
    "c_why_what_labels = test_labels[test_labels == 0]\n",
    "c_why_what_predictions = predictions[test_labels == 0]\n",
    "\n",
    "# Calculate accuracy for c-why and c-what combined category\n",
    "c_why_what_accuracy = accuracy_score(c_why_what_labels, c_why_what_predictions)\n",
    "print(\"Accuracy (c-why and c-what):\", c_why_what_accuracy)\n",
    "\n",
    "# Verify the shapes of the training and test sets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Test set shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cfdec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
